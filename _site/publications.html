<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hao Fei - Publications</title>
  <meta name="description" content="Hao Fei -- Publications.">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">
  <link rel="canonical" href="http://localhost:4000/publications">
<link rel="shortcut icon" type ="image/x-icon" href="http://localhost:4000/images/favicon.ico">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
    <a class="navbar-brand" href="http://localhost:4000/"><strong style="color:#05C4B9;">Hao</strong> Fei</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li><a href="http://localhost:4000/research">Research</a></li>
		<li><a href="http://localhost:4000/publications">Publication</a></li>
<!--		<li><a href="http://localhost:4000/projects">Project</a></li>-->
		<li><a href="http://localhost:4000/outputs">Output</a></li>
		<li><a href="http://localhost:4000/services">Service</a></li>
		<li><a href="http://localhost:4000/award">Award</a></li>
		<li><a href="http://localhost:4000/misc">Misc</a></li>
	  </ul>
	</div>
  </div>
</div>



    <div class="container-fluid">
      <div class="row">
        <div id="textid" class="col-sm-12">
  <h1 id="publications">Publications</h1>

<p><code class="language-plaintext highlighter-rouge">#</code> denotes equal contribution, <code class="language-plaintext highlighter-rouge">*</code> denotes correspondence.
See full publications in <a href="https://scholar.google.com/citations?user=YGDX46AAAAAJ">Google Scholar</a>. <br />
Jump to <a href="#preprint">Preprint</a>, <a href="#survey">Survey</a>, <a href="#benchmark">Benchmark</a>, <a href="#conference">Conference</a>, <a href="#journal">Journal</a>, <a href="#others">Others</a>.</p>

<div style="margin-top: 20px"></div>

<h3 id="-preprint">▶ Preprint<a name="preprint"></a></h3>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Grounding is All You Need? Dual Temporal Grounding for Video Dialog</strong> <br />
       <em>You Qin, Wei Ji, Xinze Lan, <strong>Hao Fei</strong>, Xun Yang, Dan Guo, Roger Zimmermann, Lizi Liao </em><br />
       <strong>arXiv</strong>    2024      <a href="https://arxiv.org/abs/2410.05767">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A Survey on Benchmarks of Multimodal Large Language Models</strong> <br />
       <em>Jian Li, Weiheng Lu, <strong>Hao Fei</strong>, Meng Luo, Ming Dai, Min Xia, Yizhang Jin, Zhenye Gan, Ding Qi, Chaoyou Fu, Ying Tai, Wankou Yang, Yabiao Wang, Chengjie Wang </em><br />
       <strong>arXiv</strong>    2024      <a href="https://arxiv.org/abs/2408.08632">[paper]</a> <a href="https://github.com/swordlidev/Evaluation-Multimodal-LLMs-Survey">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Grammar Induction from Visual, Speech and Text</strong> <br />
       <em>Yu Zhao, <strong>Hao Fei</strong>, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua </em><br />
       <strong>arXiv</strong>    2024      <a href="https://arxiv.org/abs/2410.03739">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Towards Semantic Equivalence of Tokenization in Multimodal LLM</strong> <br />
       <em>Shengqiong Wu, <strong>Hao Fei</strong>, Xiangtai Li, Jiayi Ji, Hanwang Zhang, Tat-Seng Chua, Shuicheng Yan </em><br />
       <strong>arXiv</strong>    2024      <a href="https://arxiv.org/abs/2406.05127">[paper]</a> <a href="https://chocowu.github.io/SeTok-web/">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Modeling Unified Semantic Discourse Structure for High-quality Headline Generation</strong> <br />
       <em>Minghui Xu, <strong>Hao Fei</strong>, Fei Li, Shengqiong Wu, Rui Sun, Chong Teng, Donghong Ji </em><br />
       <strong>arXiv</strong>    2024      <a href="https://arxiv.org/pdf/2403.15776">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">ControlRetriever: Harnessing the Power of Instructions for Controllable Retrieval</strong> <br />
       <em>Kaihang Pan, Juncheng Li, Hongye Song, <strong>Hao Fei</strong>, Wei Ji, Shuo Zhang, Jun Lin, Xiaozhong Liu, Siliang Tang </em><br />
       <strong>arXiv</strong>    2023      <a href="https://arxiv.org/pdf/2308.10025">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Subband-based Generative Adversarial Network for Non-parallel Many-to-many Voice Conversion</strong> <br />
       <em>Jian Ma, Zhedong Zheng, <strong>Hao Fei</strong>, Feng Zheng, Tat-seng Chua, Yi Yang </em><br />
       <strong>arXiv</strong>    2022      <a href="https://arxiv.org/pdf/2207.06057.pdf">[paper]</a>  </p>

<div style="margin-top: 30px"></div>

<h3 id="-survey">▶ Survey<a name="survey"></a></h3>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A Survey on Benchmarks of Multimodal Large Language Models</strong> <br />
       <em>Jian Li, Weiheng Lu, <strong>Hao Fei</strong>, Meng Luo, Ming Dai, Min Xia, Yizhang Jin, Zhenye Gan, Ding Qi, Chaoyou Fu, Ying Tai, Wankou Yang, Yabiao Wang, Chengjie Wang </em><br />
       <strong>arXiv</strong>     2024    
  <a href="https://arxiv.org/abs/2408.08632">[paper]</a> <a href="https://github.com/swordlidev/Evaluation-Multimodal-LLMs-Survey">[data]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A Survey of Ontology Expansion for Conversational Understanding</strong> <br />
       <em>Jinggui Liang, Yuxia Wu, Yuan Fang, <strong>Hao Fei</strong>, Lizi Liao </em><br />
       <strong>EMNLP</strong>     2024    
  <a href="https://arxiv.org/abs/2410.15019">[paper]</a> <a href="https://github.com/liangjinggui/Ontology-Expansion">[data]</a></p>

<div style="margin-top: 30px"></div>

<h3 id="-benchmark">▶ Benchmark<a name="benchmark"></a></h3>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal Conversational Aspect-based Sentiment Analysis</strong> <br />
       <em>Meng Luo, <strong>Hao Fei<sup>*</sup></strong>, Bobo Li, Shengqiong Wu, Qian Liu, Soujanya Poria, Erik Cambria, Mong-Li Lee, Wynne Hsu </em><br />
       <strong>ACM MM</strong>     2024    
  <a href="https://arxiv.org/pdf/2408.09481">[paper]</a> <a href="https://panosent.github.io/">[data]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">SpeechEE: A Novel Benchmark for Speech Event Extraction</strong> <br />
       <em>Bin Wang, Meishan Zhang, <strong>Hao Fei<sup>*</sup></strong>, Yu Zhao, Bobo Li, Shengqiong Wu, Wei Ji, Min Zhang </em><br />
       <strong>ACM MM</strong>     2024    
  <a href="https://arxiv.org/abs/2408.09462">[paper]</a> <a href="https://speechee.github.io/">[data]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Recognizing Everything from All Modalities at Once: Grounded Multimodal Universal Information Extraction</strong> <br />
       <em>Meishan Zhang, <strong>Hao Fei<sup>*</sup></strong>, Bin Wang, Shengqiong Wu, Yixin Cao, Fei Li, Min Zhang </em><br />
       <strong>ACL 2024 (Findings)</strong>     2024    
  <a href="https://arxiv.org/abs/2406.03701">[paper]</a> <a href="https://haofei.vip/MUIE/">[data]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">MMLSCU: A Dataset for Multi-modal Multi-domain Live Streaming Comment Understanding</strong> <br />
       <em>Zixiang Meng, Qiang Gao, Di Guo, Yunlong Li, Bobo Li, <strong>Hao Fei</strong>, Shengqiong Wu, Fei Li, Chong Teng, Donghong Ji </em><br />
       <strong>TheWebConf (WWW)</strong>     2024    
  <a href="">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">DiaASQ: A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis</strong> <br />
       <em>Bobo Li, <strong>Hao Fei</strong>, Yuhan Wu, Jinsong Zhang, Shengqiong Wu, Jingye Li, Yijiang Liu, Lizi Liao, Tat-Seng Chua, Fei Li, Donghong Ji </em><br />
       <strong>ACL</strong>  (Findings)    2023    
  <a href="https://arxiv.org/abs/2211.05705">[paper]</a> <a href="https://diaasq-page.pages.dev/">[data]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Towards Complex-query Referring Image Segmentation: A Novel Benchmark</strong> <br />
       <em>Wei Ji, Li Li, <strong>Hao Fei<sup>*</sup></strong>, Xiangyan Liu, Xun Yang, Juncheng Li, Roger Zimmermann </em><br />
       <strong>TOMM</strong>     2024    
  <a href="https://arxiv.org/pdf/2309.17205">[paper]</a> <a href="https://github.com/lili0415/DuMoGa">[data]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">ECQED: Emotion-Cause Quadruple Extraction in Dialogs</strong> <br />
       <em>Li Zheng, Donghong Ji, <strong>Hao Fei</strong>, Shengqiong Wu, Jingye Li, Bobo Li, Chong Teng </em><br />
       <strong>Preprint</strong>     2023    
  <a href="https://arxiv.org/pdf/2306.03969.pdf">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">DialogRE^C+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs</strong> <br />
       <em>Yiyun Xiong, Mengwei Dai, Fei Li, <strong>Hao Fei</strong>, Bobo Li, Shengqiong Wu, Chong Teng and Donghong Ji </em><br />
       <strong>NLPCC</strong>     2023    
  <a href="https://arxiv.org/abs/2308.04498">[paper]</a> <a href="https://github.com/palm2333/DialogRE_coreference">[data]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Nominal Compound Chain Extraction: A New Task for Semantic-Enriched Lexical Chain</strong> <br />
       <em>Bobo Li, <strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
       <strong>NLPCC</strong>     2020    
  <a href="https://arxiv.org/abs/2009.09173">[paper]</a> <a href="https://ncce-site.pages.dev/">[data]</a></p>

<div style="margin-top: 30px"></div>

<h3 id="-conference">▶ Conference<a name="conference"></a></h3>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">VITRON: A Unified Pixel-level Vision LLM for Understanding, Generating, Segmenting, Editing</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Hanwang Zhang, Tat-Seng Chua, Shuicheng Yan </em><br />
        <strong>NeurIPS</strong>         2024 
       <a href="http://haofei.vip/downloads/papers/Skywork_Vitron_2024.pdf">[paper]</a> <a href="https://vitron-llm.github.io/">[code]</a> <a href="https://mp.weixin.qq.com/s/ef3GMQavH_K9iarSdwoxog">[新智元]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Synergistic Dual Spatial-aware Generation of Image-to-text and Text-to-image</strong> <br />
       <em>Yu Zhao, <strong>Hao Fei<sup>*</sup></strong>, Xiangtai Li, Libo Qin, Jiayi Ji, Hongyuan Zhu, Meishan Zhang, Min Zhang </em><br />
        <strong>NeurIPS</strong>         2024 
       <a href="https://arxiv.org/abs/2410.15312">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding</strong> <br />
       <em>Tao Zhang, Xiangtai Li, <strong>Hao Fei</strong>, Shengqiong Wu, Shunping Ji, Chen Change Loy, Shuicheng Yan </em><br />
        <strong>NeurIPS</strong>         2024 
       <a href="https://arxiv.org/abs/2406.19389">[paper]</a> <a href="https://lxtgh.github.io/project/omg_llava/">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation</strong> <br />
       <em>Changli Wu, Qi Chen, Haowei Wang, Yiwei Ma, You Huang, Gen Luo, <strong>Hao Fei</strong>, Jiayi Ji, Xiaoshuai Sun, Rongrong Ji </em><br />
        <strong>NeurIPS</strong>         2024 
        <strong style="color:#C7254E;">(Oral)</strong>        <a href="">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Towards Unified Multimodal Editing with Enhanced Knowledge Collaboration</strong> <br />
       <em>Kaihang Pan, Zhaoyu Fan, Juncheng Li, Qifan Yu, <strong>Hao Fei</strong>, Siliang Tang, Richang Hong, Hanwang Zhang, Qianru Sun </em><br />
        <strong>NeurIPS</strong>         2024 
        <strong style="color:#C7254E;">(Spotlight)</strong>        <a href="https://arxiv.org/abs/2409.19872">[paper]</a> <a href="https://github.com/beepkh/UniKE">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Unified Generative and Discriminative Training for Multi-modal Large Language Models</strong> <br />
       <em>Wei Chow, Juncheng Li, Kaihang Pan, Qifan Yu, <strong>Hao Fei</strong>, Zhiqi Ge, Shuaiyang, Siliang Tang, Hanwang Zhang, Qianru Sun </em><br />
        <strong>NeurIPS</strong>         2024 
       <a href="">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">ControlMLLM: Training-Free Visual Prompt Learning for Multimodal Large Language Models</strong> <br />
       <em>Mingrui Wu, Xinyue Cai, Jiayi Ji, Jiale Li, Oucheng Huang, Gen Luo, <strong>Hao Fei</strong>, Guannan Jiang, Xiaoshuai Sun, Rongrong Ji </em><br />
        <strong>NeurIPS</strong>         2024 
       <a href="https://arxiv.org/abs/2407.21534">[paper]</a> <a href="https://github.com/mrwu-mac/ControlMLLM">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">What Factors Affect Multi-modal In-Context Learning? An In-Depth Exploration</strong> <br />
       <em>Libo Qin, Qiguang Chen, <strong>Hao Fei</strong>, Zhi Chen, Min Li, Wanxiang Che </em><br />
        <strong>NeurIPS</strong>         2024 
       <a href="">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Guided Knowledge Generation with Language Models for Commonsense Reasoning</strong> <br />
       <em>Xiao Wei, Haoran Chen, Hang Yu, <strong>Hao Fei</strong>, Qian Liu </em><br />
        <strong>EMNLP</strong>      (Findings)    2024 
       <a href="">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Divide and Conquer: Legal Concept-guided Criminal Court View Generation</strong> <br />
       <em>Qi Xu, Xiao Wei, Hang Yu, Qian Liu, <strong>Hao Fei</strong> </em><br />
        <strong>EMNLP</strong>      (Findings)    2024 
       <a href="">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A Survey of Ontology Expansion for Conversational Understanding</strong> <br />
       <em>Jinggui Liang, Yuxia Wu, Yuan Fang, <strong>Hao Fei</strong>, Lizi Liao </em><br />
        <strong>EMNLP</strong>         2024 
       <a href="https://arxiv.org/abs/2410.15019">[paper]</a> <a href="https://github.com/liangjinggui/Ontology-Expansion">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal Conversational Aspect-based Sentiment Analysis</strong> <br />
       <em>Meng Luo, <strong>Hao Fei<sup>*</sup></strong>, Bobo Li, Shengqiong Wu, Qian Liu, Soujanya Poria, Erik Cambria, Mong-Li Lee, Wynne Hsu </em><br />
        <strong>ACM MM</strong>         2024 
        <strong style="color:#C7254E;">(Oral)</strong>        <a href="https://arxiv.org/pdf/2408.09481">[paper]</a> <a href="https://panosent.github.io/">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">SpeechEE: A Novel Benchmark for Speech Event Extraction</strong> <br />
       <em>Bin Wang, Meishan Zhang, <strong>Hao Fei<sup>*</sup></strong>, Yu Zhao, Bobo Li, Shengqiong Wu, Wei Ji, Min Zhang </em><br />
        <strong>ACM MM</strong>         2024 
       <a href="https://arxiv.org/abs/2408.09462">[paper]</a> <a href="https://speechee.github.io/">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Self-Adaptive Fine-grained Multi-modal Data Augmentation for Semi-supervised Muti-modal Coreference Resolution</strong> <br />
       <em>Li Zheng, Boyu Chen, <strong>Hao Fei</strong>, Fei Li, Shengqiong Wu, Lizi Liao, Donghong Ji, Chong Teng </em><br />
        <strong>ACM MM</strong>         2024 
       <a href="https://openreview.net/pdf?id=BlttBoaYVu">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">De-fine: Decomposing and Refining Visual Programs with Auto-Feedback</strong> <br />
       <em>Minghe Gao, Juncheng Li, <strong>Hao Fei</strong>, Wei Ji, Guoming Wang, Wenqiao Zhang, Siliang Tang, Yueting Zhuang </em><br />
        <strong>ACM MM</strong>         2024 
        <strong style="color:#C7254E;">(Oral)</strong>        <a href="https://arxiv.org/pdf/2311.12890">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Recognizing Everything from All Modalities at Once: Grounded Multimodal Universal Information Extraction</strong> <br />
       <em>Meishan Zhang, <strong>Hao Fei<sup>*</sup></strong>, Bin Wang, Shengqiong Wu, Yixin Cao, Fei Li, Min Zhang </em><br />
        <strong>ACL</strong>      (Findings)    2024 
       <a href="https://arxiv.org/abs/2406.03701">[paper]</a> <a href="http://haofei.vip/MUIE">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Faithful Logical Reasoning via Symbolic Chain-of-Thought</strong> <br />
       <em>Jundong Xu, <strong>Hao Fei<sup>*</sup></strong>, Liangming Pan, Qian Liu, Mong-Li Lee, Wynne Hsu </em><br />
        <strong>ACL</strong>         2024 
       <a href="https://arxiv.org/pdf/2405.18357">[paper]</a> <a href="https://github.com/Aiden0526/SymbCoT">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Revisiting Structured Sentiment Analysis as Latent Dependency Graph Parsing</strong> <br />
       <em>Chengjie Zhou, Bobo Li, <strong>Hao Fei</strong>, Fei Li, Chong Teng, Donghong Ji </em><br />
        <strong>ACL</strong>         2024 
       <a href="">[paper]</a> <a href="https://github.com/JYoen/latentssa">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">ProtT3: Protein-to-Text Generation for Text-based Protein Understanding</strong> <br />
       <em>Zhiyuan Liu, An Zhang, <strong>Hao Fei</strong>, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua </em><br />
        <strong>ACL</strong>         2024 
       <a href="https://arxiv.org/abs/2405.12564">[paper]</a> <a href="https://github.com/acharkq/ProtT3">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Synergizing Large Language Models and Pre-Trained Smaller Models for Conversational Intent Discovery</strong> <br />
       <em>Jinggui Liang, Lizi Liao, <strong>Hao Fei</strong>, Jing Jiang </em><br />
        <strong>ACL</strong>      (Findings)    2024 
       <a href="">[paper]</a> <a href="https://github.com/liangjinggui/SynCID">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Wei Ji, Hanwang Zhang, Meishan Zhang, Mong-Li Lee, Wynne Hsu </em><br />
        <strong>ICML</strong>         2024 
        <strong style="color:#C7254E;">(Oral)</strong>        <a href="http://haofei.vip/downloads/papers/VoT_2024.pdf">[paper]</a> <a href="http://haofei.vip/VoT/">[code]</a> <a href="https://mp.weixin.qq.com/s/K5qqCj-g7FpXPM3AGewgYg">[机器之心]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">NExT-GPT: Any-to-Any Multimodal LLM</strong> <br />
       <em>Shengqiong Wu, <strong>Hao Fei<sup>*</sup></strong>, Leigang Qu, Wei Ji, Tat-Seng Chua </em><br />
        <strong>ICML</strong>         2024 
        <strong style="color:#C7254E;">(Oral, Most Influential Papers by Paper Digest (ICML 2024),  2024 WAIC Youth Outstanding Paper Award)</strong>        <a href="https://arxiv.org/pdf/2309.05519">[paper]</a> <a href="https://next-gpt.github.io/">[code]</a> <a href="https://mp.weixin.qq.com/s/rE24QWdOFlYhMk7v3tv-fg">[新智元]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Momentor: Advancing Video Large Language Model with Fine-Grained Temporal Reasoning</strong> <br />
       <em>Long Qian, Juncheng Li, Yu Wu, Yaobo Ye, <strong>Hao Fei</strong>, Tat-Seng Chua, Yueting Zhuang, Siliang Tang </em><br />
        <strong>ICML</strong>         2024 
       <a href="https://arxiv.org/pdf/2402.11435">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Multi-view Counterfactual Contrastive Learning for Fact-checking Fake News Detection</strong> <br />
       <em>Yongcheng Zhang, Lingou Kong, Sheng Tian, <strong>Hao Fei</strong>, Changpeng Xiang, Huan Wang, Xiaomei Wei </em><br />
        <strong>ICMR</strong>         2024 
       <a href="">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery</strong> <br />
       <em>Jinggui Liang, Lizi Liao, <strong>Hao Fei</strong>, Bobo Li, Jing Jiang </em><br />
        <strong>NAACL</strong>         2024 
       <a href="">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations</strong> <br />
       <em>Meng Luo, Han Zhang, Shengqiong Wu, Bobo Li, Hong Han, <strong>Hao Fei<sup>*</sup></strong> </em><br />
        <strong>SemEval Workshop</strong>         2024 
        <strong style="color:#C7254E;">(2nd Place)</strong>        <a href="http://haofei.vip/downloads/papers/SemEval_2024_Task3_v3.pdf">[paper]</a> <a href="https://github.com/zhanghanXD/NUS-Emo-at-SemEval-2024-Task3">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">I3: Intent-Introspective Retrieval Conditioned on Instructions</strong> <br />
       <em>Kaihang Pan, Juncheng Li, Wenjie Wang, <strong>Hao Fei</strong>, Hongye Song, Wei Ji, Jun Lin, Xiaozhong Liu, Tat-Seng Chua, Siliang Tang </em><br />
        <strong>SIGIR</strong>         2024 
       <a href="https://arxiv.org/pdf/2308.10025v2">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Dysen-VDM: Empowering Dynamics-aware Text-to-Video Diffusion with LLMs</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Wei Ji, Hanwang Zhang, Tat-Seng Chua </em><br />
        <strong>CVPR</strong>         2024 
       <a href="https://arxiv.org/pdf/2308.13812.pdf">[paper]</a> <a href="https://haofei.vip/Dysen-VDM/">[code]</a> <a href="https://mp.weixin.qq.com/s/dmCcSesfsy1UGBy9mHXr9A">[PaperWeekly]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding, Reasoning, and Planning</strong> <br />
       <em>Sijin Chen, Xin Chen, Chi Zhang, Mingsheng Li, Gang Yu, <strong>Hao Fei</strong>, Hongyuan Zhu, Jiayuan Fan, Tao Chen </em><br />
        <strong>CVPR</strong>         2024 
       <a href="https://arxiv.org/pdf/2311.18651">[paper]</a> <a href="https://github.com/Open3DA/LL3DA">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">What Factors Influence LLMs’ Judgments? A Case Study on Question Answering</strong> <br />
       <em>Lei Chen, Bobo Li, Li Zheng, Haining Wang, Zixiang Meng, Runfeng Shi, <strong>Hao Fei</strong>, Jun Zhou, Fei Li, Chong Teng and Donghong Ji </em><br />
        <strong>COLING</strong>         2024 
       <a href="https://aclanthology.org/2024.lrec-main.1519.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">MMLSCU: A Dataset for Multi-modal Multi-domain Live Streaming Comment Understanding</strong> <br />
       <em>Zixiang Meng, Qiang Gao, Di Guo, Yunlong Li, Bobo Li, <strong>Hao Fei</strong>, Shengqiong Wu, Fei Li, Chong Teng, Donghong Ji </em><br />
        <strong>TheWebConf (WWW)</strong>         2024 
       <a href="">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">In-Context Learning for Few-Shot Nested Named Entity Recognition</strong> <br />
       <em>Meishan Zhang, Bin Wang, <strong>Hao Fei<sup>*</sup></strong>, Min Zhang </em><br />
        <strong>ICASSP</strong>         2024 
       <a href="https://arxiv.org/pdf/2402.01182">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Reverse Multi-Choice Dialogue Commonsense Inference with Graph-of-Thought</strong> <br />
       <em>Li Zheng, <strong>Hao Fei</strong>, Fei Li1, Bobo Li, Lizi Liao, Donghong Ji, Chong Teng </em><br />
        <strong>AAAI</strong>         2024 
       <a href="https://arxiv.org/pdf/2312.15291.pdf">[paper]</a> <a href="https://github.com/ZhengL00/ReX-GoT">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Harnessing Holistic Discourse Features and Triadic Interaction for Sentiment Quadruple Extraction in Dialogues</strong> <br />
       <em>Bobo Li, <strong>Hao Fei</strong>, Lizi Liao, Yu Zhao, Fangfang Su, Fei Li, Donghong Ji </em><br />
        <strong>AAAI</strong>         2024 
       <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29807">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Improving Expressive Power of Spectral Graph Neural Networks with Eigenvalue Correction</strong> <br />
       <em>Kangkang Lu, Yanhua Yu, <strong>Hao Fei</strong>, Xuan Li, Zixuan Yang, Zirui Guo, Meiyu Liang, Mengran Yin, Tat-Seng Chua </em><br />
        <strong>AAAI</strong>         2024 
       <a href="https://arxiv.org/pdf/2401.15603">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Molca: Molecular graph-language modeling with cross-modal projector and uni-modal adapter</strong> <br />
       <em>Zhiyuan Liu, Sihang Li, Yanchen Luo, <strong>Hao Fei</strong>, Yixin Cao, Kenji Kawaguchi, Xiang Wang, Tat-Seng Chua </em><br />
        <strong>EMNLP</strong>         2023 
       <a href="https://arxiv.org/pdf/2310.12798">[paper]</a> <a href="https://github.com/acharkq/molca">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">VPGTrans: Transfer Visual Prompt Generator across LLMs</strong> <br />
       <em>Ao Zhang, <strong>Hao Fei<sup>*</sup></strong>, <strong>Yuan Yao<sup>*</sup></strong>, Wei Ji, Li Li, Zhiyuan Liu, Tat-Seng Chua </em><br />
        <strong>NeurIPS</strong>         2023 
       <a href="https://arxiv.org/pdf/2305.01278.pdf">[paper]</a> <a href="https://vpgtrans.github.io/">[code]</a> <a href="https://mp.weixin.qq.com/s/7Pf1PCZKdpyWOLdUyBH-Bw">[新智元]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Imagine That! Abstract-to-Intricate Text-to-Image Synthesis with Scene Graph Hallucination Diffusion</strong> <br />
       <em>Shengqiong Wu, <strong>Hao Fei<sup>*</sup></strong>, Hanwang Zhang, Tat-Seng Chua </em><br />
        <strong>NeurIPS</strong>         2023 
       <a href="https://neurips.cc/virtual/2023/poster/70785">[paper]</a> <a href="https://github.com/ChocoWu/T2I-Salad">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation</strong> <br />
       <em>Leigang Qu, Shengqiong Wu, <strong>Hao Fei<sup>*</sup></strong>, Liqiang Nie, Tat-Seng Chua </em><br />
        <strong>ACM MM</strong>         2023 
       <a href="https://arxiv.org/pdf/2308.05095.pdf">[paper]</a> <a href="https://layoutllm-t2i.github.io/">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition</strong> <br />
       <em>Bobo Li, <strong>Hao Fei</strong>, Lizi Liao, Yu Zhao, Chong Teng, Tat-Seng Chua, Donghong Ji, Fei Li </em><br />
        <strong>ACM MM</strong>         2023 
       <a href="https://arxiv.org/pdf/2308.04502.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic Role Labeling</strong> <br />
       <em>Yu Zhao, <strong>Hao Fei<sup>*</sup></strong>, Yixin Cao, Bobo Li, Meishan Zhang, Jianguo Wei, Min Zhang, Tat-Seng Chua </em><br />
        <strong>ACM MM</strong>         2023 
       <a href="https://arxiv.org/pdf/2308.05081.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Partial Annotation-based Video Moment Retrieval via Iterative Learning</strong> <br />
       <em>Wei Ji, Renjie Liang, Lizi Liao, <strong>Hao Fei<sup>*</sup></strong>, Fuli Feng </em><br />
        <strong>ACM MM</strong>         2023 
       <a href="\#">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">DialogRE^C+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs</strong> <br />
       <em>Yiyun Xiong, Mengwei Dai, Fei Li, <strong>Hao Fei</strong>, Bobo Li, Shengqiong Wu, Chong Teng and Donghong Ji </em><br />
        <strong>NLPCC</strong>         2023 
       <a href="https://arxiv.org/pdf/2308.04498.pdf">[paper]</a> <a href="https://github.com/palm2333/DialogRE_coreference">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Reasoning Implicit Sentiment with Chain-of-Thought Prompting</strong> <br />
       <em><strong>Hao Fei</strong>, Bobo Li, Qian Liu, Lidong Bing, Fei Li, Tat-Seng Chua </em><br />
        <strong>ACL</strong>      (Short)    2023 
       <a href="https://arxiv.org/pdf/2205.10346.pdf">[paper]</a> <a href="https://github.com/scofield7419/THOR-ISA">[code]</a> <a href="https://mp.weixin.qq.com/s/IwWHK5heDEG2blMVoDhVdw">[Paperweakly]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination</strong> <br />
       <em><strong>Hao Fei</strong>, Qian Liu, Meishan Zhang, Min Zhang, Tat-Seng Chua </em><br />
        <strong>ACL</strong>         2023 
       <a href="https://arxiv.org/pdf/2305.12256.pdf">[paper]</a> <a href="https://github.com/scofield7419/UMMT-VSH">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Constructing Code-mixed Universal Dependency Forest for Unbiased Cross-lingual Relation Extraction</strong> <br />
       <em><strong>Hao Fei</strong>, Meishan Zhang, Min Zhang, Tat-Seng Chua </em><br />
        <strong>ACL</strong>      (Findings)    2023 
       <a href="https://arxiv.org/pdf/2305.12258.pdf">[paper]</a> <a href="https://github.com/scofield7419/XLSIE/">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Information Screening whilst Exploiting! Multimodal Relation Extraction with Feature Denoising and Multimodal Topic Modeling</strong> <br />
       <em>Shengqiong Wu, <strong>Hao Fei<sup>*</sup></strong>, Yixin Cao, Lidong Bing, Tat-Seng Chua </em><br />
        <strong>ACL</strong>         2023 
        <strong style="color:#C7254E;">(Paper Award Nomination, 1.6%)</strong>        <a href="https://arxiv.org/pdf/2305.11719.pdf">[paper]</a> <a href="https://github.com/ChocoWu/MRE-ISE">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Cross2StrA: Unpaired Cross-lingual Image Captioning with Cross-lingual Cross-modal Structure-pivoted Alignment</strong> <br />
       <em>Shengqiong Wu, <strong>Hao Fei<sup>*</sup></strong>, Wei Ji, Tat-Seng Chua </em><br />
        <strong>ACL</strong>         2023 
       <a href="https://arxiv.org/pdf/2305.12260.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Generating Visual Spatial Description via Holistic 3D Scene Understanding</strong> <br />
       <em>Yu Zhao, <strong>Hao Fei<sup>*</sup></strong>, Wei Ji, Jianguo Wei, Meishan Zhang, Min Zhang, Tat-Seng Chua </em><br />
        <strong>ACL</strong>         2023 
       <a href="https://arxiv.org/pdf/2305.11768.pdf">[paper]</a> <a href="https://github.com/zhaoyucs/VSD">[code]</a> <a href="https://mp.weixin.qq.com/s/cGtE_ouAC67sutj7ekuN8w">[Paperweakly]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">DiaASQ: A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis</strong> <br />
       <em>Bobo Li, <strong>Hao Fei</strong>, Yuhan Wu, Jinsong Zhang, Shengqiong Wu, Jingye Li, Yijiang Liu, Lizi Liao, Tat-Seng Chua, Fei Li, Donghong Ji </em><br />
        <strong>ACL</strong>      (Findings)    2023 
       <a href="https://arxiv.org/pdf/2211.05705.pdf">[paper]</a> <a href="https://github.com/unikcc/DiaASQ">[code]</a> <a href="https://mp.weixin.qq.com/s/Fxf_9X72K5v-JgMzGpw7rA">[Paperweakly]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Jingye Li, Bobo Li, Fei Li, Libo Qin, Meishan Zhang, Min Zhang, Tat-Seng Chua </em><br />
        <strong>NeurIPS</strong>         2022 
        <strong style="color:#C7254E;">(Spotlight)</strong>        <a href="https://arxiv.org/pdf/2304.06248.pdf">[paper]</a> <a href="https://github.com/ChocoWu/LasUIE">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Matching Structure for Dual Learning</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Yafeng Ren, Meishan Zhang </em><br />
        <strong>ICML</strong>         2022 
       <a href="https://proceedings.mlr.press/v162/fei22a.html">[paper]</a> <a href="https://github.com/scofield7419/StruMatchDL">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Effective Token Graph Modeling using a Novel Labeling Strategy for Structured Sentiment Analysis</strong> <br />
       <em>Wenxuan Shi, Fei Li, Jingye Li, <strong>Hao Fei</strong>, Donghong Ji </em><br />
        <strong>ACL</strong>         2022 
       <a href="https://arxiv.org/pdf/2203.10796.pdf">[paper]</a> <a href="https://github.com/Xgswlg/TGLS">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Unified Named Entity Recognition as Word-Word Relation Classification</strong> <br />
       <em>Jingye Li<sup>#</sup>, <strong>Hao Fei<sup>#</sup></strong>, Jiang Liu, Shengqiong Wu, Meishan Zhang, Donghong Ji, Fei Li </em><br />
        <strong>AAAI</strong>         2022 
        <strong style="color:#C7254E;">(Most Influential Papers by Paper Digest (AAAI 2022))</strong>        <a href="https://arxiv.org/pdf/2112.10070.pdf">[paper]</a> <a href="https://github.com/ljynlp/W2NER">[code]</a> <a href="https://mp.weixin.qq.com/s/CAcuYe2s_Yag4Xg8POIEvA">[Paperweekly]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Mastering the Explicit Opinion-role Interaction: Syntax-aided Neural Transition System for Unified Opinion Role Labeling</strong> <br />
       <em>Shengqiong Wu, <strong>Hao Fei<sup>*</sup></strong>, Fei Li, Donghong Ji, Meishan Zhang, Yijiang Liu, Chong Teng </em><br />
        <strong>AAAI</strong>         2022 
       <a href="https://arxiv.org/pdf/2112.10070.pdf">[paper]</a> <a href="https://www.aaai.org/AAAI22Papers/AAAI-729.WuS.pdf">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Mutual Disentanglement Learning for Joint Fine-Grained Sentiment Classification and Controllable Text Generation</strong> <br />
       <em><strong>Hao Fei</strong>, Chenliang Li, Donghong Ji, Fei Li </em><br />
        <strong>SIGIR</strong>         2022 
       <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3532029">[paper]</a> <a href="https://github.com/scofield7419/DualFGSC-SG">[code]</a> <a href="https://mp.weixin.qq.com/s/Tw7T7SbPPOG7RlDxqEpbkA">[情感计算]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Making Decision like Human: Joint Aspect Category Sentiment Analysis and Rating Prediction with Fine-to-Coarse Reasoning</strong> <br />
       <em><strong>Hao Fei</strong>, Jingye Li, Yafeng Ren, Meishan Zhang, Donghong Ji </em><br />
        <strong>TheWebConf (WWW)</strong>         2022 
       <a href="https://dl.acm.org/doi/10.1145/3485447.3512024">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Global Inference with Explicit Syntactic and Discourse Structures for Dialogue-Level Relation Extraction</strong> <br />
       <em><strong>Hao Fei</strong>, Jingye Li, Shengqiong Wu, Chenliang Li, Donghong Ji and Fei Li </em><br />
        <strong>IJCAI</strong>         2022 
       <a href="https://www.ijcai.org/proceedings/2022/0570.pdf">[paper]</a> <a href="https://github.com/scofield7419/DiaRE-D2G">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Inheriting the Wisdom of Predecessors: A Multiplex Cascade Framework for Unified Aspect-based Sentiment Analysis</strong> <br />
       <em><strong>Hao Fei</strong>, Fei Li, Chenliang Li, Shengqiong Wu, Jingye Li and Donghong Ji </em><br />
        <strong>IJCAI</strong>         2022 
       <a href="https://www.ijcai.org/proceedings/2022/0572.pdf">[paper]</a> <a href="https://github.com/scofield7419/UABSA-SyMux">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Conversational Semantic Role Labeling with Predicate-Oriented Latent Graph</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Meishan Zhang, Yafeng Ren and Donghong Ji </em><br />
        <strong>IJCAI</strong>         2022 
       <a href="https://arxiv.org/pdf/2210.03037.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Entity-centered Cross-document Relation Extraction</strong> <br />
       <em>Fengqi Wang, Fei Li, <strong>Hao Fei</strong>, Jingye Li, Shengqiong Wu, Fangfang Su, Wenxuan Shi, Donghong Ji, Bo Cai </em><br />
        <strong>EMNLP</strong>         2022 
       <a href="https://arxiv.org/pdf/2210.16541.pdf">[paper]</a> <a href="https://github.com/MakiseKuurisu/ecrim">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Conversation Disentanglement with Bi-Level Contrastive Learning</strong> <br />
       <em>Chengyu Huang, Zheng Zhang, <strong>Hao Fei</strong>, Lizi Liao </em><br />
        <strong>EMNLP</strong>      (Findings)    2022 
       <a href="https://arxiv.org/pdf/2210.15265.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Joint Alignment of Multi-Task Feature and Label Spaces for Emotion Cause Pair Extraction</strong> <br />
       <em>Shunjie Chen, Xiaochuan Shi, Jingye Li, Shengqiong Wu, <strong>Hao Fei</strong>, Fei Li, Donghong Ji </em><br />
        <strong>COLING</strong>         2022 
       <a href="https://arxiv.org/pdf/2209.04112.pdf">[paper]</a> <a href="https://github.com/csj199813/A2Net_ECPE">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction</strong> <br />
       <em>Hu Cao, Jingye Li, Fangfang Su, Fei Li, <strong>Hao Fei</strong>, Shengqiong Wu, Bobo Li, Liang Zhao, Donghong Ji </em><br />
        <strong>COLING</strong>         2022 
       <a href="https://arxiv.org/pdf/2209.02693.pdf">[paper]</a> <a href="https://github.com/Cao-Hu/OneEE">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Prompt-Based Generative Multi-label Emotion Prediction with Label Contrastive Learning</strong> <br />
       <em>Yuyang Chai, Chong Teng, <strong>Hao Fei</strong>, Shengqiong Wu, Jingye Li, Ming Cheng, Donghong Ji, Fei Li </em><br />
        <strong>NLPCC</strong>         2022 
       <a href="https://link.springer.com/chapter/10.1007/978-3-031-17120-8_43">[paper]</a> <a href="https://github.com/yychai74/Generative-MultiEmo">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Learn from Syntax: Improving Pair-wise Aspect and Opinion Terms Extraction with Rich Syntactic Knowledge</strong> <br />
       <em>Shengqiong Wu<sup>#</sup>, <strong>Hao Fei<sup>#</sup></strong>, Yafeng Ren, Donghong Ji, Jingye Li </em><br />
        <strong>IJCAI</strong>         2021 
       <a href="https://arxiv.org/pdf/2112.10070.pdf">[paper]</a> <a href="https://github.com/ChocoWu/Synfue-PAOTE">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Rethinking Boundaries: End-To-End Recognition of Discontinuous Mentions with Pointer Networks</strong> <br />
       <em><strong>Hao Fei</strong>, Donghong Ji, Bobo Li, Yijiang Liu, Yafeng Ren, Fei Li </em><br />
        <strong>AAAI</strong>         2021 
       <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17513/17320">[paper]</a> <a href="https://github.com/scofield7419/DisNER-PtrNet">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Encoder-Decoder Based Unified Semantic Role Labeling with Label-Aware Syntax</strong> <br />
       <em><strong>Hao Fei</strong>, Fei Li, Bobo Li, Donghong Ji </em><br />
        <strong>AAAI</strong>         2021 
       <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17514/17321">[paper]</a> <a href="https://github.com/scofield7419/LAGCN-SRL">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">End-to-end Semantic Role Labeling with Neural Transition-based Model</strong> <br />
       <em><strong>Hao Fei</strong>, Meishan Zhang, Bobo Li, Donghong Ji </em><br />
        <strong>AAAI</strong>         2021 
       <a href="https://arxiv.org/pdf/2101.00394.pdf">[paper]</a> <a href="https://github.com/scofield7419/TransitionSRL">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Better Combine Them Together! Integrating Syntactic Constituency and Dependency Representations for Semantic Role Labeling</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Yafeng Ren, Fei Li and Donghong Ji </em><br />
        <strong>ACL</strong>      (Findings)    2021 
       <a href="https://aclanthology.org/2021.findings-acl.49.pdf">[paper]</a> <a href="https://github.com/scofield7419/hesyfu">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">MRN: A Locally and Globally Mention-Based Reasoning Network for Document-Level Relation Extraction</strong> <br />
       <em>Jingye Li, Kang Xu, Fei Li, <strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
        <strong>ACL</strong>      (Findings)    2021 
       <a href="https://aclanthology.org/2021.findings-acl.117.pdf">[paper]</a> <a href="https://github.com/ljynlp/mrn">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Latent Target-Opinion as Prior for Document-Level Sentiment Classification: A Variational Approach from Fine-Grained Perspective</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Bobo Li, Shengqiong Wu, Donghong Ji </em><br />
        <strong>TheWebConf (WWW)</strong>         2021 
       <a href="https://dl.acm.org/doi/10.1145/3442381.3449789">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Latent Emotion Memory for Multi-Label Emotion Classification</strong> <br />
       <em><strong>Hao Fei</strong>, Yue Zhang, Yafeng Ren, Donghong Ji </em><br />
        <strong>AAAI</strong>         2020 
       <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6271/6127">[paper]</a> <a href="https://github.com/Baxelyne/LEM">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Cross-Lingual Semantic Role Labeling with High-Quality Translated Training Corpus</strong> <br />
       <em><strong>Hao Fei</strong>, Meishan Zhang, Donghong Ji </em><br />
        <strong>ACL</strong>         2020 
       <a href="https://aclanthology.org/2020.acl-main.627.pdf">[paper]</a> <a href="https://github.com/scofield7419/XSRL-ACL">[code]</a> <a href="https://mp.weixin.qq.com/s/T-FBWJMPZWo03SxUrTvJUw">[社媒派SMP]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Modeling Local Contexts for Joint Dialogue Act Recognition and Sentiment Classification with Bi-channel Dynamic Convolutions</strong> <br />
       <em>Jingye Li, <strong>Hao Fei</strong>, Donghong Ji </em><br />
        <strong>COLING</strong>         2020 
       <a href="https://aclanthology.org/2020.coling-main.53.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Retrofitting Structure-aware Transformer Language Model for End Tasks</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
        <strong>EMNLP</strong>         2020 
       <a href="https://aclanthology.org/2020.emnlp-main.168.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Mimic and Conquer: Heterogeneous Tree Structure Distillation for Syntactic NLP</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
        <strong>EMNLP</strong>      (Findings)    2020 
       <a href="https://aclanthology.org/2020.findings-emnlp.18.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Improving Text Understanding via Deep Syntax-Semantics Communication</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
        <strong>EMNLP</strong>      (Findings)    2020 
       <a href="https://aclanthology.org/2020.findings-emnlp.8.pdf">[paper]</a>  </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Nominal Compound Chain Extraction: A New Task for Semantic-Enriched Lexical Chain</strong> <br />
       <em>Bobo Li, <strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
        <strong>NLPCC</strong>         2020 
       <a href="https://arxiv.org/pdf/2009.09173.pdf">[paper]</a> <a href="https://github.com/unikcc/NCCE">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Aggressive Language Detection with Joint Text Normalization via Adversarial Multi-task Learning</strong> <br />
       <em>Shengqiong Wu, <strong>Hao Fei</strong>, Donghong Ji </em><br />
        <strong>NLPCC</strong>         2020 
       <a href="https://arxiv.org/pdf/2009.09174.pdf">[paper]</a> <a href="https://github.com/ChocoWu/ALD-TN">[code]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Implicit Objective Network for Emotion Detection</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
        <strong>NLPCC</strong>         2019 
       <a href="https://link.springer.com/chapter/10.1007/978-3-030-32233-5_50">[paper]</a>  </p>

<div style="margin-top: 30px"></div>

<h3 id="-journal">▶ Journal<a name="journal"></a></h3>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Towards Complex-query Referring Image Segmentation: A Novel Benchmark</strong> <br />
       <em>Wei Ji, Li Li, <strong>Hao Fei<sup>*</sup></strong>, Xiangyan Liu, Xun Yang, Juncheng Li, Roger Zimmermann </em><br />
       ACM Transactions on Multimedia Computing, Communications and Applications (<strong>TOMM</strong>)    2024    
  <a href="https://arxiv.org/pdf/2309.17205">[paper]</a> <a href="https://github.com/lili0415/DuMoGa">[code]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Revisiting Conversation Discourse for Dialogue Disentanglement</strong> <br />
       <em>Bobo Li, <strong>Hao Fei<sup>*</sup></strong>, Fei Li, Shengqiong Wu, Lizi Liao, Yinwei Wei, Tat-Seng Chua, Donghong Ji </em><br />
       ACM Transactions on Information Systems (<strong>TOIS</strong>)    2024    
  <a href="https://arxiv.org/pdf/2306.03975.pdf">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Multimodal Emotion-Cause Pair Extraction with Holistic Interaction and Label Constraint</strong> <br />
       <em>Bobo Li, <strong>Hao Fei</strong>, Fei Li, Tat-Seng Chua, Donghong Ji </em><br />
       ACM Transactions on Multimedia Computing, Communications and Applications (<strong>TOMM</strong>)    2024    
  <a href="https://dl.acm.org/doi/abs/10.1145/3689646">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">S3 Agent: Unlocking the Power of VLLM for Zero-Shot Multi-modal Sarcasm Detection</strong> <br />
       <em>Peng Wang, Yongheng Zhang, <strong>Hao Fei</strong>, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng Lu, Min Li, Libo Qin </em><br />
       ACM Transactions on Multimedia Computing, Communications and Applications (<strong>TOMM</strong>)    2024    
  <a href="https://dl.acm.org/doi/abs/10.1145/3690642">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan </em><br />
       IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)    2024    
  <a href="https://ieeexplore.ieee.org/abstract/document/10508488">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">TKDP: Threefold Knowledge-enriched Deep Prompt Tuning for Few-shot Named Entity Recognition</strong> <br />
       <em>Jiang Liu, <strong>Hao Fei</strong>, Fei Li, Jingye Li, Bobo Li, Liang Zhao, Chong Teng, Donghong Ji </em><br />
       IEEE Transactions on Knowledge and Data Engineering (<strong>TKDE</strong>)    2024    
  <a href="https://arxiv.org/pdf/2306.03974.pdf">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Knowledge-enhanced event relation extraction via event ontology prompt</strong> <br />
       <em>Ling Zhuang<sup>#</sup>, <strong>Hao Fei<sup>#</sup></strong>, Po Hu </em><br />
       Information Fusion     2023    
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S156625352300235X">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Syntax-based Dynamic Latent Graph for Event Relation Extraction</strong> <br />
       <em>Ling Zhuang, <strong>Hao Fei</strong>, Po Hu </em><br />
       Information Processing &amp; Management (<strong>IPM</strong>)    2023    
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457323002066">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">On the Robustness of Aspect-based Sentiment Analysis: Rethinking Model, Data, and Training</strong> <br />
       <em><strong>Hao Fei</strong>, Tat-Seng Chua, Chenliang Li, Donghong Ji, Meishan Zhang, Yafeng Ren </em><br />
       ACM Transactions on Information Systems (<strong>TOIS</strong>)    2023    
  <a href="https://arxiv.org/pdf/2304.09563.pdf">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Nonautoregressive encoder-decoder neural framework for end-to-end aspect-based sentiment triplet extraction</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Yue Zhang, Donghong Ji </em><br />
       IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>)    2023    
  <a href="https://ieeexplore.ieee.org/abstract/document/9634849">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Optimizing Attention for Sequence Modeling via Reinforcement Learning</strong> <br />
       <em><strong>Hao Fei</strong>, Yue Zhang, Yafeng Ren, Donghong Ji </em><br />
       IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>)    2022    
  <a href="https://ieeexplore.ieee.org/document/9352534">[paper]</a> <a href="https://github.com/scofield7419/DRGA">[code]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A semantic and syntactic enhanced neural model for financial sentiment analysis</strong> <br />
       <em>Chunli Xiang, Junchi Zhang, Fei Li, <strong>Hao Fei</strong>, Donghong Ji </em><br />
       Information Processing &amp; Management (<strong>IPM</strong>)    2022    
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457322000656">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Enriching contextualized language model from knowledge graph for biomedical information extraction</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Yue Zhang, Donghong Ji, Xiaohui Liang </em><br />
       Briefings in Bioinformatics (<strong>BiB</strong>)    2021    
  <a href="https://academic.oup.com/bib/article-pdf/22/3/bbaa110/37963251/bbaa110.pdf">[paper]</a> <a href="https://github.com/Baxelyne/BioKGLM">[code]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A span-graph neural model for overlapping entity relation extraction in biomedical texts</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Yue Zhang, Donghong Ji, Xiaohui Liang </em><br />
       Bioinformatics     2021    
  <a href="https://academic.oup.com/bioinformatics/article-pdf/37/11/1581/50360951/btaa993.pdf">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Second-Order Semantic Role Labeling With Global Structural Refinement</strong> <br />
       <em><strong>Hao Fei</strong>, Shengqiong Wu, Yafeng Ren, Donghong Ji </em><br />
       IEEE/ACM Transactions on Audio, Speech and Language Processing (<strong>TASLP</strong>)    2021    
  <a href="https://ieeexplore.ieee.org/document/9439066">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">High-Order Pair-Wise Aspect and Opinion Terms Extraction With Edge-Enhanced Syntactic Graph Convolution</strong> <br />
       <em>Shengqiong Wu, <strong>Hao Fei</strong>, Yafeng Ren, Bobo Li, Fei Li, Donghong Ji </em><br />
       IEEE/ACM Transactions on Audio, Speech and Language Processing (<strong>TASLP</strong>)    2021    
  <a href="https://ieeexplore.ieee.org/document/9478183">[paper]</a> <a href="https://github.com/ChocoWu/ESGCN-AOP">[code]</a></p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Topic-Enhanced Capsule Network for Multi-Label Emotion Classification</strong> <br />
       <em><strong>Hao Fei</strong>, Donghong Ji, Yue Zhang, Yafeng Ren </em><br />
       IEEE/ACM Transactions on Audio, Speech and Language Processing (<strong>TASLP</strong>)    2020    
  <a href="https://ieeexplore.ieee.org/document/9113297">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Cross-Lingual Semantic Role Labeling With Model Transfer</strong> <br />
       <em><strong>Hao Fei</strong>, Meishan Zhang, Fei Li, Donghong Ji </em><br />
       IEEE/ACM Transactions on Audio, Speech and Language Processing (<strong>TASLP</strong>)    2020    
  <a href="https://ieeexplore.ieee.org/document/9165903">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Boundaries and edges rethinking: An end-to-end neural model for overlapping entity relation extraction</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
       Information Processing &amp; Management (<strong>IPM</strong>)    2020    
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457320308062?via%3Dihub">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A tree-based neural network model for biomedical event trigger detection</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
       Information Sciences     2020    
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025519309247?via%3Dihub">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Dispatched attention with multi-task learning for nested mention recognition</strong> <br />
       <em><strong>Hao Fei</strong>, Yafeng Ren, Donghong Ji </em><br />
       Information Sciences     2020    
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025519310333?via%3Dihub">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A deep neural network model for speakers coreference resolution in legal texts</strong> <br />
       <em>Donghong Ji, Jun Gao, <strong>Hao Fei</strong>, Chong Teng, Yafeng Ren </em><br />
       Information Processing &amp; Management (<strong>IPM</strong>)    2020    
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457320308608?via%3Dihub">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">An end-to-end joint model for evidence information extraction from court record document</strong> <br />
       <em>Donghong Ji, Peng Tao, <strong>Hao Fei</strong>, Yafeng Ren </em><br />
       Information Processing &amp; Management (<strong>IPM</strong>)    2020    
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457320308001?via%3Dihub">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">A hybrid neural network model for predicting kidney disease in hypertension patients based on electronic health records</strong> <br />
       <em>Yafeng Ren<sup>#</sup>, <strong>Hao Fei<sup>#</sup></strong>, Xiaohui Liang, Donghong Ji, Ming Cheng </em><br />
       BMC Medical Informatics &amp; Decision Making (<strong>MIDM</strong>)    2019    
  <a href="https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0765-4">[paper]</a> </p>

<div style="margin-top: 30px"></div>

<h3 id="-others-demos-workshops-challenges-tutorials">▶ Others (Demos, Workshops, Challenges, Tutorials)<a name="others"></a></h3>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">EmpathyEar: An Open-source Avatar Multimodal Empathetic Chatbot</strong> <br />
       <em><strong>Hao Fei</strong>, Han Zhang, Bin Wang, Lizi Liao, Qian Liu, Erik Cambria </em><br />
       <strong>ACL</strong>  (Demo)    2024    
  <a href="https://arxiv.org/abs/2406.15177">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">XNLP: An Interactive Demonstration System for Universal Structured NLP</strong> <br />
       <em><strong>Hao Fei</strong>, Meishan Zhang, Min Zhang, Tat-Seng Chua </em><br />
       <strong>ACL</strong>  (Demo)    2024    
  <a href="https://arxiv.org/abs/2308.01846">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">From Multimodal LLM to Human-level AI: Modality, Instruction, Reasoning, Efficiency and Beyond</strong> <br />
       <em><strong>Hao Fei</strong>, Yuan Yao, Zhuosheng Zhang, Fuxiao Liu, Ao Zhang, Tat-Seng Chua </em><br />
       <strong>COLING</strong>  (Tutorial)    2024    
  <a href="https://mllm2024.github.io/CVPR2024/">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations</strong> <br />
       <em>Meng Luo, Han Zhang, Shengqiong Wu, Bobo Li, Hong Han, <strong>Hao Fei<sup>*</sup></strong> </em><br />
       <strong>SemEval @ ACL</strong>  (Challenge, 2nd Place)    2024    
  <a href="https://aclanthology.org/2024.semeval-1.226.pdf">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Deep Multimodal Learning for Generation and Retrieval</strong> <br />
       <em>Wei Ji, <strong>Hao Fei</strong>, Yinwei Wei, Zhedong Zheng, Juncheng Li, Zhiqi Ge, Long Chen, Lizi Liao, Yueting Zhuang, Roger Zimmermann </em><br />
       <strong>ACM MM</strong>  (Workshop)    2024    
  <a href="https://videorelation.nextcenter.org/MMGR24/">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">Deep Multimodal Learning for Information Retrieval</strong> <br />
       <em>Wei Ji, Yinwei Wei, Zhedong Zheng, <strong>Hao Fei</strong>, Tat-seng Chua </em><br />
       <strong>ACM MM</strong>  (Workshop)    2023    
  <a href="https://videorelation.nextcenter.org/MMIR23/">[paper]</a> </p>

<p><span style="font-size: 20px;">•</span>   <strong style="font-size: 17px;">On the Syntax-oriented Modeling and Optimization of Natural Language</strong> <br />
       <em><strong>Hao Fei</strong> </em><br />
       <strong>Ph.D Thesis</strong>     2021    
  <a href="\#">[paper]</a> </p>


</div>

      </div>
    </div>

    <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">

	  <div class="row" style="width: 100%;text-align: center">
		<div class="col-sm-3">
<!--		  <p>&copy2023 Hao Fei. Powered by <a href="http://jekyllrb.com/">Jekyll</a></p>-->
<!--			<p>Powered by <a href="http://jekyllrb.com/">Jekyll</a> </p>-->
<!--		   <p>&copy2023 <a href="http://localhost:4000/"> Hao Fei</a>.</p>-->

		</div>
<!--		<center>-->
		<div class="col-sm-6" >
			  <p style="text-align: center">&copy2024 <a href="http://localhost:4000/"> Hao Fei</a>. &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;
				Powered by <a href="http://jekyllrb.com/">Jekyll</a>.&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;
			  <span id="busuanzi_container_site_pv"><a href=""><span id="busuanzi_value_site_uv"></span></a> visits.</span></p>

<!--			<p>Contact me via email: <a href="mailto:haofei37@nus.edu.sg" target="_blank">haofei37@nus.edu.sg</a></p>-->
		</div>
<!--		</center>-->
		<div class="col-sm-4">
<!--			<span id="busuanzi_container_site_pv">-->
<!--				The site has been visited <span id="busuanzi_value_site_pv"></span> times.-->
<!--				The site visited <a href=""><span id="busuanzi_value_site_pv"></span></a> times.-->
<!--				Visiting <a href=""><span id="busuanzi_value_site_uv"></span></a> times.-->
<!--			</span>-->
<!--			  Coordinates: <br/>-->
<!--				  5 Prince George's Park, Singapore 118404<br/>-->
<!--				  National University of Singapore<br/>-->
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="http://localhost:4000/js/bootstrap.min.js"></script>


  </body>

</html>

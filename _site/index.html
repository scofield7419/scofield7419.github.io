<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hao Fei - Home</title>
  <meta name="description" content="Hao Fei - Home">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">
  <link rel="canonical" href="http://localhost:4000/">
<link rel="shortcut icon" type ="image/x-icon" href="http://localhost:4000/images/favicon.ico">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
    <a class="navbar-brand" href="http://localhost:4000/"><strong style="color:#05C4B9;">Hao</strong> Fei</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li><a href="http://localhost:4000/research">Research</a></li>
		<li><a href="http://localhost:4000/publications">Publication</a></li>
<!--		<li><a href="http://localhost:4000/projects">Project</a></li>-->
		<li><a href="http://localhost:4000/outputs">Output</a></li>
		<li><a href="http://localhost:4000/services">Service</a></li>
		<li><a href="http://localhost:4000/award">Award</a></li>
		<li><a href="http://localhost:4000/misc">Misc</a></li>
	  </ul>
	</div>
  </div>
</div>



    <div class="container-fluid">
      <div class="row">
        <div id="homeid" class="col-sm-8">

<table>
    <tbody>
        <tr>
            <td width="35%">
              <a id="profile" href="http://localhost:4000/"><img src="http://localhost:4000/images/teampic/feihao-potriat.jpg" class="img-responsive" width="90%" style="block:inline; margin-left:auto; margin-right:auto; margin-top:20px; margin-bottom:20px;" /></a>
            </td>
            <td>
                <div id="toptitle" style="margin-left: 20px">
                    <h1>Hao Fei </h1>
                    <h3>Research Fellow </h3>
                    School of Computing, National University of Singapore  <br />
                    3 Research Link, Singapore 117602  <br />
                    <div style="margin-top: 15px;margin-left: -80px">
                        <center>
                            
                            <a href="mailto:haofei7419@gmail.com" target="_blank"><i class="fa fa-envelope-square fa-2x"></i></a> 
                            <a href="mailto:haofei37@nus.edu.sg" target="_blank"><i class="fa fa-envelope-square fa-2x"></i></a> 
                             <a href="https://github.com/scofield7419" target="_blank"><i class="fa fa-github-square fa-2x"></i></a> 
                             <a href="https://dblp.uni-trier.de/pid/81/3569-1.html" target="_blank"><i class="ai ai-dblp-square ai-2x"></i></a> 
                             <a href="https://scholar.google.com/citations?user=YGDX46AAAAAJ" target="_blank"><i class="ai ai-google-scholar-square ai-2x"></i></a> 
                             <a href="https://www.researchgate.net/profile/Hao-Fei-2" target="_blank"><i class="ai ai-researchgate-square ai-2x"></i></a> 
                             <a href="https://www.semanticscholar.org/author/Hao-Fei/46959445" target="_blank"><i class="ai ai-semantic-scholar-square ai-2x"></i></a> 
                             <a href="https://www.linkedin.com/in/%E8%B1%AA-%E8%B4%B9-27769b140/" target="_blank"><i class="fa fa-linkedin-square fa-2x"></i></a> 
                             <a href="https://github.com/scofield7419/cv/blob/master/haofei-cv.pdf" target="_blank"><i class="ai ai-cv-square ai-2x"></i></a> 
                        </center>
                    </div>
                </div>
            </td>
        </tr>
    </tbody>
</table>

<h3 id="profile">Profile</h3>
<p class="text-justify">I am a research fellow at National University of Singapore, working with Prof. <a href="https://www.comp.nus.edu.sg/~leeml/">Mong-Li Lee</a> and Prof. <a href="https://www.comp.nus.edu.sg/~whsu/">Wynne Hsu</a> at <a href="https://ids.nus.edu.sg/">IDS</a>, also partially with Prof. <a href="https://www.chuatatseng.com/">Tat-Seng Chua</a> at <a href="https://www.nextcenter.org">NExT++</a>.
Previously, I was an associate researcher at Skywork AI Singapore, working with Prof. <a href="https://yanshuicheng.info/">Shuicheng Yan</a> (more previously an associate researcher at SEA AI lab).
I graduated as Ph.D from Wuhan University.</p>

<p class="text-justify">My research has been published in top-tier ML/NLP/CV/MM venues, e.g., ICML, NeurIPS, ACL, CVPR, AAAI, WWW, SIGIR, IJCAI, EMNLP, ACM-MM, TPAMI, TKDE, TOIS, TNNLS, TASLP. 
I was awarded the World AI Conference Rising Star in 2023. 
His papers were selected as Most Influential Papers by Paper Digest, and ESI Highly Influential Papers and 2024 WAIC Outstanding Paper Award.
I was also the recipient of the 2023 WAIC Rising Star award, and ranked as Top 2% Scientists Worldwide 2024 (Single Year) by Stanford University.
I’ve regularly served as (Senior) Area Chair or Senior Program Committee of top-tier conferences.
I was the organization committee of WSDM 2022, EMNLP 2023, ACL 2024. 
I serve as the Associate Editor of some journals, including TALLIP and Neurocomputing.
And I am a persistently-invited reviewer for many journals including TPAMI, IJCV, TNNLS, TKDE, TOIS, etc. 
My Ph.D thesis was awarded the Excellent Doctoral Thesis of Chinese Information Processing Society (CIPS). 
I won more than ten honors and awards when I was in Ph.D stage.</p>

<div style="margin-top: 20px"></div>

<h3 id="research">Research</h3>

<p class="text-justify">My research interests lie in the NLP, CV, and the intersection of both (i.e., Multimodal/Vision-Language Learning).
My long-term goal is to achieve human-level AI centering around multimodal LLMs &amp; generalists.
While previously I worked a lot on the topic of <a href="http://localhost:4000/sail">Structural Modeling of Language&amp;Vision</a>, I pay the most recent focus on the unified multimodal generalist towards human-level capacity (Modality, Task, Knowledge) and cognition (Reasoning, Affection), with following key topics and representative works (detailed in <a href="http://localhost:4000/research">research statement</a>):</p>

<div style="border-radius: 0.7em;background-color: rgba(0,0,0,3%);padding-bottom: 0.0pt;padding-left: 4.0pt;padding-right: 4.0pt;padding-top: 4.0pt;">

  <p>▶  <strong><code class="language-plaintext highlighter-rouge">Multimodal Foundation Models</code></strong>: <em>Unified multimodal LLMs and generalists.</em></p>
  <ul>
    <li><a href="https://next-gpt.github.io/"><strong>NExT-GPT</strong></a>:      <em style="font-size: 15px;color:#C7254E;">The 1st unified any-to-any multimodal LLM</em></li>
    <li><a href="https://vitron-llm.github.io/"><strong>Vitron</strong></a>:      <em style="font-size: 15px;color:#C7254E;">The 1st unified pixel-level vision LLM for understanding, generating, segmenting, editing of image and video</em></li>
    <li><a href="https://path2generalist.github.io/"><strong>General-Level</strong></a>:      <em style="font-size: 15px;color:#C7254E;">Pioneer the path of MLLM evaluations towards multimodal generalists</em></li>
    <li><a href="https://mllm2024.github.io/ACM-MM2024/"><strong>MLLM tutorial</strong></a>:      <em style="font-size: 15px;color:#C7254E;">A pioneering tutorial series for MLLM techniques</em></li>
  </ul>
</div>

<div style="border-radius: 0.7em;background-color: rgba(0,0,0,3%);padding-bottom: 0.0pt;padding-left: 4.0pt;padding-right: 4.0pt;padding-top: 4.0pt;">

  <p>▶  <strong><code class="language-plaintext highlighter-rouge">Capacity</code></strong>: <em>Perception/generation of modalities/tasks, knowledge acquisition/information extraction.</em></p>
  <ul>
    <li><a href="https://haofei.vip/Dysen-VDM/"><strong>Dysen-VDM</strong></a>:      <em style="font-size: 15px;color:#C7254E;">Enhance temporal dynamics of text-to-video diffusion from LLMs</em></li>
    <li><a href="https://layoutllm-t2i.github.io/"><strong>LayoutLLM-T2I</strong></a>:      <em style="font-size: 15px;color:#C7254E;">Enhance fidelity of text-to-image diffusion with layout from LLMs</em></li>
    <li><a href="https://arxiv.org/abs/2406.19255"><strong>Finsta</strong></a>:      <em style="font-size: 15px;color:#C7254E;">Enhance VLMs with a fine-grained structural spatio-temporal alignment learning</em></li>
    <li><a href="https://haofei.vip/MUIE/"><strong>MUIE</strong></a>:      <em style="font-size: 15px;color:#C7254E;">The 1st benchmark for grounded multimodal universal information extraction</em></li>
  </ul>
</div>

<div style="border-radius: 0.7em;background-color: rgba(0,0,0,3%);padding-bottom: 0.0pt;padding-left: 4.0pt;padding-right: 4.0pt;padding-top: 4.0pt;">

  <p>▶  <strong><code class="language-plaintext highlighter-rouge">Cognition</code></strong>: <em>Cross-modal complex neuro/symbolic reasoning and human-centric affective computing.</em></p>
  <ul>
    <li><a href="https://haofei.vip/VoT/"><strong>Video-of-Thought</strong></a>:      <em style="font-size: 15px;color:#C7254E;">The 1st video chain-of-thought reasoning framework</em></li>
    <li><a href="https://github.com/Aiden0526/SymbCoT"><strong>SymbCoT</strong></a>:      <em style="font-size: 15px;color:#C7254E;">The 1st fully LLM-based logical reasoning framework based on chain-of-thought</em></li>
    <li><a href="https://haofei.vip/THOR/"><strong>THOR-ISA</strong></a>:      <em style="font-size: 15px;color:#C7254E;">The 1st chain-of-thought reasoning framework for implicit sentiment analysis</em></li>
    <li><a href="https://panosent.github.io/"><strong>PanoSent</strong></a>:      <em style="font-size: 15px;color:#C7254E;">The 1st cognitive-level benchmark for multimodal conversational aspect-based sentiment analysis</em></li>
  </ul>
</div>

<div style="margin-top: 20px"></div>

<h3 id="advertising">Advertising</h3>

<p class="text-justify"><strong>I am constantly looking for collaborations</strong> on the above topics. 
Remote manner is also supported.
For promising students I will provide sufficient GPUs.
Hit me up, if you are a Ph.D/master/bachelor student and interested in what I am doing now.
When you are from Chinese universities, there are also potential vacancies for research interns (e.g., self-/CSC-funded joint PhD project).
Please describe your research status and attach your resume.</p>


</div>
<div id="newsid" class="col-sm-4" >

<div class="well">
<h3>News</h3>

<div style="margin-top: 20px"></div>



<span style="font-size: 23px;">&#8226;</span> &nbsp; <strong style="font-size: 18px;">2 Nov 2024</strong><br><p>The tutorial video record of <a href="https://mllm2024.github.io/ACM-MM2024/"><strong>Multimodal LLM</strong></a> at <a href="https://2024.acmmm.org/"><strong>ACM MM 2024</strong></a> are released at <a href="https://www.youtube.com/watch?v=hjBGytR9sP4"><strong>Youtube</strong></a>; all slides and materials are available at <a href="https://mllm2024.github.io/ACM-MM2024/"><strong>homepage</strong></a>.</p>


<span style="font-size: 23px;">&#8226;</span> &nbsp; <strong style="font-size: 18px;">25 Oct 2024</strong><br><p>We will give a tutorial at <a href="https://2024.acmmm.org/"><strong>ACM MM 2024</strong></a> on <strong>Monday 28 Oct 9:00-12:30</strong>, on the hot topic of <a href="https://mllm2024.github.io/ACM-MM2024/"><strong>MLLMs: Architecture, Modality, Function, Instruction, Hallucination, Evaluation, Reasoning and Beyond</strong></a>. Please stay tuned to the <a href="https://mllm2024.github.io/ACM-MM2024/">program</a> and welcome on-site or online attendance.</p>


<span style="font-size: 23px;">&#8226;</span> &nbsp; <strong style="font-size: 18px;">26 Sep 2024</strong><br><p>Eight papers are accepted by NeurIPS 2024, all about Multimodal LLMs and Learnings. Congrats to all my co-authors!</p>


<span style="font-size: 23px;">&#8226;</span> &nbsp; <strong style="font-size: 18px;">20 Sep 2024</strong><br><p>Three papers are accepted by EMNLP 2024 (Main/Findings), 1) <a href="#"><strong>Commonsense Reasoning</strong></a>, 2) <a href="#"><strong>Legal Text Generation</strong></a>, and 3) <a href="#"><strong>Survey on Conversational Understanding</strong></a>. Congrats to all my co-authors!</p>


<span style="font-size: 23px;">&#8226;</span> &nbsp; <strong style="font-size: 18px;">16 Sep 2024</strong><br><p>Ranked as Top 2% Scientists Worldwide 2024 (Single Year) by Stanford University.</p>


<span style="font-size: 23px;">&#8226;</span> &nbsp; <strong style="font-size: 18px;">16 July 2024</strong><br><p>Four papers are accepted by ACM MM 2024, 1) <a href="#"><strong>Multimodal Conversational ABSA</strong></a>, 2) <a href="#"><strong>Speech Event Extraction</strong></a>, 3) <a href="#"><strong>Mutimodal Coreference Resolution</strong></a> and 4) <a href="https://arxiv.org/pdf/2311.12890"><strong>Visual Programs</strong></a>. Congrats to all my co-authors!</p>


<span style="font-size: 23px;">&#8226;</span> &nbsp; <strong style="font-size: 18px;">19 June 2024</strong><br><p>Our tutorial video of <a href="https://mllm2024.github.io/CVPR2024/"><strong>Multimodal LLM</strong></a> at <a href="https://cvpr.thecvf.com/Conferences/2024/"><strong>CVPR 2024</strong></a> is released at <a href="https://www.youtube.com/watch?v=pHBT3zXxQX8"><strong>Youtube</strong></a>; all slides and materials are available at <a href="https://mllm2024.github.io/CVPR2024/"><strong>homepage</strong></a>.</p>




<!--<p  style="text-align: justify"></p>-->


<h4><a href="http://localhost:4000/news">... see all News</a></h4>

  
<!-- <div style="margin-top: 32px"></div> -->
<!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=b6e0dd&w=240&t=n&d=HHR0os3rRmH5M4XiHNDaDvtIJdBCADmPgZtg5l8aZEk&co=fafafa&cmo=ca254e&cmn=fca747&ct=00d6b9'></script> -->

  
  
<!-- <div style="margin-top: -22px"></div> -->

</div>

</div>
<div id="visits" class="col-sm-4" style="height:182">
<div class="well" style="height:182">

<div style="margin-top: 5px"></div>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=b6e0dd&w=240&t=n&d=HHR0os3rRmH5M4XiHNDaDvtIJdBCADmPgZtg5l8aZEk&co=fafafa&cmo=ca254e&cmn=fca747&ct=00d6b9'></script>

  
  
<div style="margin-top: -22px"></div>

</div>

</div>


      </div>
    </div>

    <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">

	  <div class="row" style="width: 100%;text-align: center">
		<div class="col-sm-3">
<!--		  <p>&copy2023 Hao Fei. Powered by <a href="http://jekyllrb.com/">Jekyll</a></p>-->
<!--			<p>Powered by <a href="http://jekyllrb.com/">Jekyll</a> </p>-->
<!--		   <p>&copy2023 <a href="http://localhost:4000/"> Hao Fei</a>.</p>-->

		</div>
<!--		<center>-->
		<div class="col-sm-6" >
			  <p style="text-align: center">&copy2024 <a href="http://localhost:4000/"> Hao Fei</a>. &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;
				Powered by <a href="http://jekyllrb.com/">Jekyll</a>.&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;
			  <span id="busuanzi_container_site_pv"><a href=""><span id="busuanzi_value_site_uv"></span></a> visits.</span></p>

<!--			<p>Contact me via email: <a href="mailto:haofei37@nus.edu.sg" target="_blank">haofei37@nus.edu.sg</a></p>-->
		</div>
<!--		</center>-->
		<div class="col-sm-4">
<!--			<span id="busuanzi_container_site_pv">-->
<!--				The site has been visited <span id="busuanzi_value_site_pv"></span> times.-->
<!--				The site visited <a href=""><span id="busuanzi_value_site_pv"></span></a> times.-->
<!--				Visiting <a href=""><span id="busuanzi_value_site_uv"></span></a> times.-->
<!--			</span>-->
<!--			  Coordinates: <br/>-->
<!--				  5 Prince George's Park, Singapore 118404<br/>-->
<!--				  National University of Singapore<br/>-->
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="http://localhost:4000/js/bootstrap.min.js"></script>


  </body>

</html>
